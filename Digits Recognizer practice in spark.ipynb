{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark=SparkSession \\\n               .builder \\\n               .appName('SparkApp') \\\n               .getOrCreate()\n       # config(master='<ipaddress of master . to be used in acluster mode>' ) \\"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["spark"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["from pyspark.sql.types import StructType, StructField, StringType, IntegerType,FloatType"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["training=spark.read.csv(path='/FileStore/tables/data_mnist.csv',header=True,inferSchema=True)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["training.printSchema()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["type(training)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["display(training)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["training.columns[1:]"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["vectorassembler=VectorAssembler(inputCols=(training.columns[1:]),outputCol='features')\ntraining = vectorassembler.transform(training)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["from pyspark.ml.classification import RandomForestClassifier"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["(trainingData, testData) = training.randomSplit([0.7, 0.3])"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\",maxDepth = 30)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["model=rf.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["predictions = model.transform(testData)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["predictions.show(5)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["evaluator = MulticlassClassificationEvaluator(labelCol=\"label\")"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["accuracy = evaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["accuracy"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":21}],"metadata":{"name":"ML spark","notebookId":4126639013304636},"nbformat":4,"nbformat_minor":0}
